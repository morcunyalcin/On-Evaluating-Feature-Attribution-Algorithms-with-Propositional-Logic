{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "from sympy import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import string\n",
    "import operator\n",
    "from sympy.logic.boolalg import is_dnf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import shap\n",
    "import lime\n",
    "import lime.lime_tabular\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HELPER FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate boolean formula using number of variables(string length), number of clauses, length of individual clauses and likelihood of negations\n",
    "def give_formula(num_string,num_clauses,length_clause,prob_neg):\n",
    "    complement = ['~','']\n",
    "    L= list(map(lambda i: ('t' + str(i)), range(num_string)))\n",
    "    V= list(map(lambda i: Symbol('t' + str(i)), range(num_string)))\n",
    "    dd = dict(zip(L,V))\n",
    "    globals().update(dd)\n",
    "    expression = str() # expression\n",
    "    condition = True\n",
    "    while condition:      # Continue to run until generated formula contains all atomic variables we defined in the string\n",
    "        for i in range(num_clauses):\n",
    "            variable_list = random.choices(L, k = length_clause)\n",
    "            local_expression = str()\n",
    "            for ind,variable in enumerate(variable_list):\n",
    "                if(ind != length_clause - 1):\n",
    "                    local_expression += random.choices(complement,cum_weights = [prob_neg,100-prob_neg],k=1)[0] + str(variable) + '&' \n",
    "                else:\n",
    "                    local_expression += random.choices(complement,cum_weights = [prob_neg,100-prob_neg],k=1)[0] + str(variable)\n",
    "            if(i != num_clauses - 1):\n",
    "                expression += local_expression + '|'\n",
    "            else:\n",
    "                expression += local_expression\n",
    "        c = all(ele in expression for ele in L) # Check whether formula contain or not all atomic variables\n",
    "        condition = not c\n",
    "    dnf_expression = (eval(expression)) \n",
    "    return dnf_expression,V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create instances based on the size of the dataset and length of the string\n",
    "def create_instances(size,bits):\n",
    "    instances = []\n",
    "    for i in range(size):\n",
    "        s = np.random.randint(2, size= bits).tolist()     \n",
    "        instances.append(s)\n",
    "        instances = [list(y) for y in set([tuple(x) for x in instances])]\n",
    "    return instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check whether boolean formula is satisfiable or not under the assignment\n",
    "def satisfiable(instance,tuple_variables,dnf_expression):\n",
    "    mapping_features = {variable:(True if feature == 1 else False) for feature,variable in zip(instance,tuple_variables)}\n",
    "    sat = dnf_expression.subs(mapping_features)\n",
    "    return sat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label instances to POS or NEG based on their satisfiability under the assignment\n",
    "def find_labels(instances,expression,variables):\n",
    "    labels = []\n",
    "    for s in instances:\n",
    "        sat = satisfiable(s,variables,expression)\n",
    "        labels.append(sat)\n",
    "    return labels    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find each individual clause in the DNF form of the boolean formula\n",
    "def find_clauses(expr):\n",
    "    expr = to_dnf(expr,True)\n",
    "    if not isinstance(expr, Or):\n",
    "        return expr\n",
    "    return expr.args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the dataframe containing predictor features(binary values of the string) and target feature(satisfiability of the assignment) \n",
    "def create_dataframe(size,labels,instances):\n",
    "    features = [str(feature) for feature in range(1,size+1)]\n",
    "    df = pd.DataFrame(instances, columns= features)\n",
    "    df['Target'] = labels\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create mapping feeature dictionary to call atomic variables based on their indexes\n",
    "def map_from_index_to_features(num_string,variables): \n",
    "    index_features = [i for i in range(0,num_string)]\n",
    "    mapping_features = {index:argument for argument,index in zip(variables,index_features)}\n",
    "    return mapping_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the maximal explanation accuracy of SHAP\n",
    "def max_explanation_score_shap(max_explanation_dataset,mapping_features,shap_values,instance_index):\n",
    "    indexes = []\n",
    "    for  proposition in max_explanation_dataset[instance_index]: # Find the indexes of the atomic variables in explanation dataset.\n",
    "        i = list(mapping_features.keys())[list(mapping_features.values()).index(proposition)]\n",
    "        indexes.append(i)\n",
    "    len_pro = len(indexes)   # Find the number of atomic variables in the explanation dataset\n",
    "    shaps = shap_values[1][0].argsort() # Sort the Shapley Values. If you want to use other ensemble tree models like XGBoost or Adaboost, please change 'shap_values[1][0]' part to 'shap_values[0]'\n",
    "    highest_rankings = shaps[-len_pro:] # Highest k Shap values \n",
    "    score = len(list(set(indexes).intersection(highest_rankings)))/len_pro # Find the common atomic variables in explanation dataset and highest k shap values\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the minimal explanation accuracy of SHAP\n",
    "def min_explanation_score_shap(min_explanation_dataset,mapping_features,shap_values,instance_index):\n",
    "    indexes = []\n",
    "    for  proposition in min_explanation_dataset[instance_index]: # Find the indexes of the atomic variables in explanation dataset.\n",
    "        i = list(mapping_features.keys())[list(mapping_features.values()).index(proposition)]\n",
    "        indexes.append(i)\n",
    "    len_pro = len(indexes) # Find the number of atomic variables in the explanation dataset.\n",
    "    if(len_pro == 0): # If minimal explanation set is empty, we remove it from the general accuracy calculation.\n",
    "        return 'N'\n",
    "    else:\n",
    "        shaps = shap_values[1][0].argsort() # Sort the Shapley Values. If you want to use other ensemble tree models like XGBoost or Adaboost, please change 'shap_values[1][0]' part to 'shap_values[0]'\n",
    "        highest_rankings = shaps[-len_pro:] # Highest k Shap values \n",
    "        score = len(list(set(indexes).intersection(highest_rankings)))/len_pro # Find the common atomic variables in explanation dataset and highest k shap values\n",
    "        return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the individual explanation accuracy of SHAP\n",
    "def indexp_shap(ind_explanation_dataset,mapping_features,shap_values,instance_index):\n",
    "    scores = []\n",
    "    for ind_clause in ind_explanation_dataset[instance_index]:\n",
    "        indexes = []\n",
    "        for  proposition in ind_clause:\n",
    "            i = list(mapping_features.keys())[list(mapping_features.values()).index(proposition)]\n",
    "            indexes.append(i)\n",
    "            len_pro = len(indexes)   # Find the number of atomic variables in the satisfiable individual clauses\n",
    "            shaps = shap_values[1][0].argsort() # Sort the Shapley Values. If you want to use other ensemble tree models like XGBoost or Adaboost, please change 'shap_values[1][0]' part to 'shap_values[0]'\n",
    "            highest_rankings = shaps[-len_pro:] # Highest k Shap values \n",
    "            score = len(list(set(indexes).intersection(highest_rankings)))/len_pro\n",
    "            scores.append(score)\n",
    "    best = max(scores) # Give the best score\n",
    "    return best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total performance score for the dataset\n",
    "def total_performance_explanation(truth_table):\n",
    "    truth_table = [i for i in truth_table if i != 'N'] \n",
    "    performance = np.mean(truth_table)\n",
    "    return performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the maximal explanation accuracy of LIME\n",
    "def max_explanation_score_lime(max_explanation_dataset,mapping_features,sorted_list,instance_index):\n",
    "    indexes = [] \n",
    "    for proposition in max_explanation_dataset[instance_index]:  # Find the indexes of the atomic variables in explanation dataset.\n",
    "        i = list(mapping_features.keys())[list(mapping_features.values()).index(proposition)]\n",
    "        indexes.append(i)\n",
    "    len_pro = len(indexes) # Find the number of atomic variables in the explanation dataset.\n",
    "    sorted_weights = [tuple_index[0] for tuple_index in sorted_list] # Sorted LIME weights\n",
    "    highest_rankings = sorted_weights[:len_pro]   # Highest k LIME weights  \n",
    "    score = len(list(set(indexes).intersection(highest_rankings)))/len_pro # Find the common atomic variables in explanation dataset and highest k LIME weights\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the maximal explanation accuracy of LIME\n",
    "def min_explanation_score_lime(min_explanation_dataset,mapping_features,sorted_list,instance_index):\n",
    "    indexes = [] \n",
    "    for proposition in min_explanation_dataset[instance_index]:  # Find the indexes of the atomic variables in explanation dataset.\n",
    "        i = list(mapping_features.keys())[list(mapping_features.values()).index(proposition)]\n",
    "        indexes.append(i)\n",
    "    len_pro = len(indexes) # Find the number of atomic variables in the explanation dataset.\n",
    "    if(len_pro == 0):  # If minimal explanation set is empty, we remove it from the general accuracy calculation.\n",
    "        return 'N'\n",
    "    else:\n",
    "        sorted_weights = [tuple_index[0] for tuple_index in sorted_list] # Sorted LIME weights\n",
    "        highest_rankings = sorted_weights[:len_pro]   # Highest k LIME weights  \n",
    "        score = len(list(set(indexes).intersection(highest_rankings)))/len_pro # Find the common atomic variables in explanation dataset and highest k LIME weights\n",
    "        return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the individual explanation accuracy of SHAP\n",
    "def indexp_lime(ind_explanation_dataset,mapping_features,sorted_list,instance_index):\n",
    "    scores = []\n",
    "    for ind_clause in ind_explanation_dataset[instance_index]:\n",
    "        indexes = []\n",
    "        for  proposition in ind_clause:\n",
    "            i = list(mapping_features.keys())[list(mapping_features.values()).index(proposition)]\n",
    "            indexes.append(i)\n",
    "            len_pro = len(indexes)   # Find the number of atomic variables in the satisfiable individual clauses\n",
    "            sorted_weights = [tuple_index[0] for tuple_index in sorted_list] # Sorted LIME weights\n",
    "            highest_rankings = sorted_weights[:len_pro]   # Highest k LIME weights\n",
    "            score = len(list(set(indexes).intersection(highest_rankings)))/len_pro # Find the common atomic variables in explanation dataset and highest k LIME weights\n",
    "            scores.append(score)\n",
    "    best = max(scores)\n",
    "    return best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BINARY CLASSIFICATION PART"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "instances = create_instances(5000,25)  # Create instances\n",
    "expression,variables = expression,variables = give_formula(25,40,6,25) # Generate boolean formula\n",
    "labels = find_labels(instances,expression,variables) # Label instances POS and NEG based on their satisfiability on boolean formula\n",
    "clauses = find_clauses(expression)  # Find core asssigments(satisfiable individual clauses in the DNF form of the formula)\n",
    "mapping_features = map_from_index_to_features(25,variables) # Map atomic variables into the their indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_explanation_dataset = []\n",
    "min_explanation_dataset = []\n",
    "labels_dataframe = []\n",
    "ind_explanation_dataset = []\n",
    "for i,l in zip(instances,labels):\n",
    "    if l == False:                             # If the instance is not satisfiable, its explanation is empty. \n",
    "        max_explanation_dataset.append(0)\n",
    "        min_explanation_dataset.append(0)\n",
    "        ind_explanation_dataset.append(0)\n",
    "        labels_dataframe.append(0)\n",
    "    else:                                     # Find the explanation set of the instance which is satisfiable\n",
    "        labels_dataframe.append(1)\n",
    "        max_explanation = []\n",
    "        min_explanation = []\n",
    "        ind_explanation = []\n",
    "        t = 0\n",
    "        for clause in clauses:\n",
    "            clause_sat = satisfiable(i,variables,clause)       # Check the clause is satisfiable or not\n",
    "            if clause_sat == True:\n",
    "                ind_explanation.append(clause.atoms())         # Find individual explanations\n",
    "                t += 1\n",
    "                max_explanation.extend(list(clause.atoms()))   # Find maximal explanations\n",
    "                if(t == 1):\n",
    "                    min_explanation.extend(list(clause.atoms())) # Find minimal explanations\n",
    "                else:\n",
    "                    min_explanation = list(set(min_explanation).intersection(list(clause.atoms())))\n",
    "            else:\n",
    "                continue\n",
    "        max_explanation_dataset.append(list(set(max_explanation)))\n",
    "        min_explanation_dataset.append(list(set(min_explanation)))\n",
    "        ind_explanation_dataset.append(ind_explanation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = create_dataframe(25,labels_dataframe,instances) # Create dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataframe into the training and testing sets\n",
    "y = df['Target']\n",
    "X = df.drop(['Target'],1)\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size = 0.2 ,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classifier\n",
    "clf_rf = RandomForestClassifier(n_estimators=150)\n",
    "clf_rf.fit(X_train, y_train)\n",
    "y_pred_rf = clf_rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXPLANATION PART - SHAP/LIME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting feature_perturbation = \"tree_path_dependent\" because no background data was given.\n"
     ]
    }
   ],
   "source": [
    "# Treeexplainer for the ensemble model\n",
    "explainer_rf = shap.TreeExplainer(clf_rf,feature_perturbation = \"tree_path_dependent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main block for SHAP explanation\n",
    "y_tst = y_test.tolist()\n",
    "index_test = []\n",
    "for items in y_test.iteritems():\n",
    "    index_test.append(items)\n",
    "truth_table_shap_max = []\n",
    "truth_table_shap_min = []\n",
    "truth_table_shap_ind = []\n",
    "for i in range(len(y_test)):\n",
    "    if(y_pred_rf[i] == 1 and y_tst[i] == 1):     #If positive instance is labeled positively by classifier\n",
    "        instance_index = index_test[i][0]        # Take the index value for the instance\n",
    "        choosen_instance = X_test.loc[[instance_index]] \n",
    "        shap_values = explainer_rf.shap_values(choosen_instance) # Shap value of the instance\n",
    "        score_shap_max = max_explanation_score_shap(max_explanation_dataset,mapping_features,shap_values,instance_index) # Find the maximal explanation score of SHAP\n",
    "        score_shap_min = min_explanation_score_shap(min_explanation_dataset,mapping_features,shap_values,instance_index) # Find the minimal explanation score of SHAP\n",
    "        score_shap_ind = indexp_shap(ind_explanation_dataset,mapping_features,shap_values,instance_index) # Find the individual explanation score of SHAP\n",
    "        truth_table_shap_max.append(score_shap_max)\n",
    "        truth_table_shap_min.append(score_shap_min)\n",
    "        truth_table_shap_ind.append(score_shap_ind)\n",
    "        performance_shap_max = total_performance_explanation(truth_table_shap_max) # Average maximal explanation score of SHAP\n",
    "        performance_shap_min = total_performance_explanation(truth_table_shap_min) # Average minimal explanation score of SHAP\n",
    "        performance_shap_ind = total_performance_explanation(truth_table_shap_ind) # Average individual explanation score of SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare feature names and target names for LIME explainer\n",
    "feature_names = X.columns.tolist()\n",
    "target_names = [0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LIME explainer for all ML models\n",
    "explainer = lime.lime_tabular.LimeTabularExplainer(X_train.values, feature_names=feature_names, class_names=target_names, discretize_continuous=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main block for LIME explanation\n",
    "def take_second(elem):  # Helper function to give the second element of the tuple\n",
    "    return elem[1]\n",
    "y_tst = y_test.tolist()\n",
    "index_test = []\n",
    "for items in y_test.iteritems():\n",
    "    index_test.append(items)\n",
    "truth_table_lime_max = []\n",
    "truth_table_lime_min = []\n",
    "truth_table_lime_ind = []\n",
    "for i in range(len(y_test)):\n",
    "    if(y_pred_rf[i] == 1 and y_tst[i] == 1):    # If positive instance is labeled positively by classifier\n",
    "        instance_index = index_test[i][0]       # Take the index value for the instance\n",
    "        exp = explainer.explain_instance(X_test.loc[instance_index], clf_rf.predict_proba, num_features= X_test.columns.shape[0], top_labels=1)\n",
    "        weights = exp.as_map()[1]        # Gives feature weights\n",
    "        sorted_list = sorted(weights, key=take_second,reverse = True)\n",
    "        score_lime_max = max_explanation_score_lime(max_explanation_dataset,mapping_features,sorted_list,instance_index) # Find the maximal explanation score of SHAP\n",
    "        score_lime_min = min_explanation_score_lime(min_explanation_dataset,mapping_features,sorted_list,instance_index) # Find the minimal explanation score of SHAP\n",
    "        score_lime_ind = indexp_lime(ind_explanation_dataset,mapping_features,sorted_list,instance_index) # Find the individual explanation score of SHAP\n",
    "        truth_table_lime_max.append(score_lime_max)\n",
    "        truth_table_lime_min.append(score_lime_min)\n",
    "        truth_table_lime_ind.append(score_lime_ind)\n",
    "        performance_lime_max = total_performance_explanation(truth_table_lime_max) # Average maximal explanation score of SHAP\n",
    "        performance_lime_min = total_performance_explanation(truth_table_lime_min) # Average minimal explanation score of SHAP\n",
    "        performance_lime_ind = total_performance_explanation(truth_table_lime_ind) # Average individual explanation score of SHAP"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
